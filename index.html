<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print" />

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Gridhowto by hornos</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Gridhowto</h1>
        <h2>Grid Ansible Slurm Centos</h2>
        <a href="https://github.com/hornos/gridhowto" class="button"><small>View project on</small>GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h1>Grid Howto</h1>

<p>This howto is for CentOS based clusters. You can try the setup in VirtualBox as well, although you will lack BMC and IB features.</p>

<p>Install ansible on the local client. Ansible should be installed into <code>$HOME/ansible</code>:</p>

<pre><code>cd $HOME
git clone git://github.com/ansible/ansible.git
</code></pre>

<p>Edit your <code>$HOME/.bashrc</code>:</p>

<pre><code>source $HOME/ansible/hacking/env-setup &amp;&gt; /dev/null
</code></pre>

<p>Run the source command:</p>

<pre><code>source $HOME/.bashrc
</code></pre>

<h2>Root servers</h2>

<p>Install gridhowto:</p>

<pre><code>cd $HOME
git clone git://github.com/hornos/gridhowto.git
</code></pre>

<p>Install at least 2 root servers for HA. Try to use multi-master setups and avoid heartbeat integration and floating addresses.</p>

<p>The following network topology is recommended for the cluster. The BMC network can be on the same interface as system (eth0). The system network is used to boot and provision the cluster.</p>

<pre><code>IF   Network  Address Range
bmc  bmc      10.0.0.0/16
eth0 system   10.1.0.0/16
eth1 storage  10.2.0.0/16
eth2 mpi      10.3.0.0/16
ethX external ?
</code></pre>

<p>The network configuration is found in <code>network.yml</code>. Each network interface can be a bond. On high-performance systems storage and mpi is InfiniBand or other high-speed network. If you have less than 4 interfaces use alias networks. Note that</p>

<h3>Root servers in VirtualBox</h3>

<p>You can make a virtual infrastructure in VirtualBox. Create the following virtual networks:</p>

<pre><code>Network   VBox Net IPv4 Addr  Mask DHCP
system    vboxnetN 10.1.1.254 16   off
storage   vboxnetM 10.2.1.254 16   off
mpi       intnet
external  NAT/Bridged
</code></pre>

<p>Setup the virtual server to have 2TB of disk 4 network cards and network boot enabled.</p>

<h2>Primordial Installation</h2>

<p>Space jockey is a very simple bootp tool. It does not compare with Cobbler or Xcat. Its main purpose is to boot and install minimal servers from your laptop, it is an entry point. Later on the root servers are used for large-scale cluster installation. You can configure root servers by ansible. In the 2nd stage Xcat or Cobbler is installed by a playbook and used to provision the compute cluster. For the primordial installation you need OS X, nginx and a dnsmasq server. To install the boot servers:</p>

<pre><code>brew install dnsmasq nginx
</code></pre>

<p>From now on all commands are relative to the <code>jockey</code> directory:</p>

<pre><code>cd $HOME/gridhowto/space
</code></pre>

<p>If you don't know which machine to boot you can check bootp requests from the root servers by:</p>

<pre><code>./jockey dump IF
</code></pre>

<p>where IF is the interface to listen on eg. vboxnet0.</p>

<p>DNSmasq is an all-inclusive DNS/DHCP/BOOTP server. Its configuration is found in the <code>masq</code> file. Edit the <code>ROOT SERVER BOOTP</code> section is you want static assignment, eg:</p>

<pre><code>dhcp-host=08:00:27:14:68:75,10.1.1.1,infinite
</code></pre>

<p>The recommended way is to put an installation DVD in each server and leave the disk in the server. You can consider it as a rescue system which is always available. All you need now is to bootstrap the installer.</p>

<p>Create the <code>boot/centos6.3</code> directory and put <code>vmlinuz</code> and <code>initrd.img</code> from the CentOS install media. Edit the <code>kickstart</code> file to customize the installation, especially <code>NETWORK</code> and <code>HOSTNAME</code> section. Put <code>pxelinux.0, chain.c32</code> from the syslinux 4.X package into <code>boot</code>.</p>

<p>Set the address of the host machine (your laptop's corresponding interface), eg.:</p>

<pre><code>./jockey host 10.1.1.254
</code></pre>

<p>Kickstart a MAC address with the installation, eg.:</p>

<pre><code>./jockey kick 08:00:27:14:68:75
</code></pre>

<p>The <code>kick</code> command creates a kickstart file in <code>boot</code> and a pxelinux configuration in <code>boot/pxelinux.cfg</code>. It also generates a root password which you can use for the stage 2 provisioning. Edit kickstarts (<code>boot/*.ks</code> files) after kicked. Root passwords are in <code>*.pass</code> files.</p>

<p>Finish the preparatin by starting the boot servers (http, dnsmasq) each in a separate terminal:</p>

<pre><code>./jockey http
./jockey boot
</code></pre>

<p>Boot servers listen on the IP you specified by the <code>host</code> command. The boot process should start now and the automatic installation continues. If finished change the boot order of the machine by:</p>

<pre><code>./jockey local 08:00:27:14:68:75
</code></pre>

<p>This command changes the pxelinux to local boot. Switch IPMI to local boot for real servers.</p>

<h3>Install from URL</h3>

<p>Mount install media and link to under <code>boot/centos6.3/repo</code>. Edit the kickstart file and change <code>cdrom</code> to:</p>

<pre><code>url --url http://10.1.1.254:8080/centos6.3/repo
</code></pre>

<h3>VNC-based Graphical Install</h3>

<p>For headless installation use VNC. Edit the corresponding file in <code>boot/pxelinux.cfg</code> and set the following kernel parameters:</p>

<pre><code>APPEND vnc ...
</code></pre>

<p>VNC is started without password. Connect your VNC client to eg. <code>10.1.1.1:1</code>.</p>

<h3>Hardware Detection</h3>

<p>For syslinux HW detection you need <code>boot/hdt.c32</code></p>

<p>Switch to detection by:</p>

<pre><code>./jockey detect 08:00:27:14:68:75 
</code></pre>

<h3>Firmware Upgrade with FreeDOS</h3>

<p>This section is based on <a href="http://wiki.gentoo.org/wiki/BIOS_Update">http://wiki.gentoo.org/wiki/BIOS_Update</a> . You have to use a linux host to create the bootdisk image. You have to download freedos tools from ibiblio.org:</p>

<pre><code>dd if=/dev/zero of=freedos bs=1024 count=20480
mkfs.msdos freedos
unzip sys-freedos-linux.zip &amp;&amp; ./sys-freedos.pl --disk=freedos
mkdir $PWD/mnt; mount -o loop freedos /mnt
</code></pre>

<p>Copy the firmware upgrade files to <code>$PWD/mnt</code> and umount the disk. Put <code>memdisk</code> and <code>freedos</code> to <code>boot</code> directory and switch to firmware (and reboot the machine):</p>

<pre><code>./jockey firmware 08:00:27:14:68:75
</code></pre>

<h3>Install ESXi 5.X</h3>

<p>You have to use syslinux 4.X . Mount ESXi install media under <code>boot/esxi/repo</code>. Put <code>mboot.c32</code> from the install media into jockey's root directory. Kickstart the machine to boot ESXi installer:</p>

<pre><code>./jockey esxi 08:00:27:14:68:75
</code></pre>

<p>Edit the kickstart file if you want to change the default settings.</p>

<h3>Other Mini-Linux Variants</h3>

<p>You can boot Cirros and Tiny Linux as well. For CirrOS put <code>initrd.img</code> and <code>vmlinuz</code> into <code>boot/cirros</code>, for Tiny Linux put <code>core.gz</code> and <code>vmlinuz</code> into <code>boot/tiny</code>, and switch eg. to Tiny:</p>

<pre><code>./jockey tiny 08:00:27:14:68:75
</code></pre>

<h3>Kickstart from scratch</h3>

<p>A good starting point for a kickstart can be found in the EAL4 package:</p>

<pre><code>cd src
wget ftp://ftp.pbone.net/mirror/ftp.redhat.com/pub/redhat/linux/eal/EAL4_RHEL5/DELL/RPMS/lspp-eal4-config-dell-1.0-1.el5.noarch.rpm
rpm2cpio lspp-eal4-config-dell-1.0-1.el5.noarch.rpm | cpio -idmv
</code></pre>

<h2>IPMI Basics</h2>

<p>If you happen to have real metal servers you need to deal with IPMI as well. Enterprise class machiens contain a small computer which you can use to remote control the machine. IPMI interfaces connect to the bmc network. Install ipmitools:</p>

<pre><code>brew install ipmitool
</code></pre>

<p>You can register IPMI users with different access levels. Connect to the remote machine with the default settings:</p>

<pre><code>ipmitool -I lanplus -U admin -P admin -H &lt;BMC IP&gt;
</code></pre>

<p>Get a remote remote console:</p>

<pre><code>xterm -e "ipmitool -I lanplus -U admin -P admin -H &lt;BMC IP&gt; sol activate"
</code></pre>

<p>Get sensor listing:</p>

<pre><code>ipmitool -I lanplus -U admin -P admin -H &lt;BMC IP&gt; sdr
</code></pre>

<h3>IPMI Management with Space Jockey</h3>

<p>Setup IPMI adresses according to the network topology. Dip OS X into the IPMI LAN:</p>

<pre><code>sudo ifconfig en0 alias 10.0.1.254 255.255.0.0
</code></pre>

<p>Set the IPMI user and password:</p>

<pre><code>./jockey ipmi user admin admin
</code></pre>

<p>Get a serial-over-lan console:</p>

<pre><code>./jockey ipmi tool 10.0.1.1 sol active
</code></pre>

<p>Get the power status:</p>

<pre><code>./jockey ipmi tool 10.0.1.1 chassis status
</code></pre>

<p>Reboot a machine:</p>

<pre><code>./jockey ipmi tool 10.0.1.1 power reset
</code></pre>

<p>Force PXE boot on the next boot only:</p>

<pre><code>./jockey ipmi tool 10.0.1.1 chassis bootdev pxe
</code></pre>

<p>Reboot the IPMI card:</p>

<pre><code>./jockey ipmi tool 10.0.1.1 mc reset cold
</code></pre>

<p>Get sensor output:</p>

<pre><code>./jockey ipmi tool 10.0.1.1 sdr list
</code></pre>

<p>Get the error log:</p>

<pre><code>./jockey ipmi tool 10.0.1.1 sel elist
</code></pre>

<h2>InfinBand Basics</h2>

<h2>Ansible Bootstrap</h2>

<p>Ansible is used to further provision root servers on the stage 2 level. Stage 2 is responsible to reach the production ready state of the grid.</p>

<p>From now on all commands are relative to <code>$HOME/gridhowto</code>:</p>

<pre><code>cd $HOME/gridhowto
</code></pre>

<p>Edit <code>hosts</code> file:</p>

<pre><code>[root]
root-01 ansible_ssh_host=10.1.1.1
root-02 ansible_ssh_host=10.1.1.2
</code></pre>

<p>Check the connection:</p>

<pre><code>ansible root-01 -i hosts -m raw -a "hostname" -u root -k
</code></pre>

<p>The bootstrap playbook creates the admin wheel user:</p>

<pre><code>ssh-keygen -f keys/admin
bin/play root-01 bootstrap.yml -k -u root
bin/play root-02 bootstrap.yml -k -u root
</code></pre>

<p>Test the bootstrap:</p>

<pre><code>bin/admin root ping -k
</code></pre>

<p>By securing the server you lock out root. Only admin is allowed to login with keys:</p>

<pre><code>bin/play root secure.yml -k --sudo
</code></pre>

<p>Reboot or shutdown the machines by:</p>

<pre><code>bin/reboot root -k
bin/shutdown root -k
</code></pre>

<p>Create a new LVM partition:</p>

<pre><code>bin/admin root run "lvcreate -l 30%FREE -n data vg_root" -k --sudo
</code></pre>

<h2>Basic Services</h2>

<p>Root servers provide NTP for the cluster. If you have a very large cluster root servers talk only to satellite servers aka rack leaders. Root servers are stratum 2 time servers. Each root server broadcasts time to the system network with crypto enabled.</p>

<p>Basic services contain NTP, Rsyslog and DNSmasq hosts cache:</p>

<pre><code>bin/play root basic.yml -k --sudo
</code></pre>

<p>Root server names are cached in <code>/etc/hosts.d/root</code>. Put DNS cache files (hosts) in <code>/etc/hosts.d</code> and notify dnsmasq to reload.</p>

<h3>EPEL Repository</h3>

<pre><code>bin/play root repo.yml -k --sudo
</code></pre>

<h3>Firewall</h3>

<pre><code>bin/play root firewall.yml -k --sudo
</code></pre>

<h2>Ganglia</h2>

<h2>Cluster FS 1</h2>

<h3>Glusterfs</h3>

<h3>DRBD</h3>

<h2>HA Mysql</h2>

<h2>HA Slurm</h2>

<h2>HA XCat</h2>

<h2>Grid</h2>

<h3>Globus</h3>

<h4>PKI</h4>

<h4>GSI-SSH</h4>

<h4>GridFTP</h4>

<h3>GateONE</h3>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/hornos/gridhowto/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/hornos/gridhowto/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/hornos/gridhowto"></a> is maintained by <a href="https://github.com/hornos">hornos</a>.</p>

          <p>This page was generated by <a href="pages.github.com">GitHub Pages</a> using the Architect theme by <a href="http://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>